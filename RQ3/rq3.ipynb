{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51754b1e-c08b-4108-987f-37e8f60b98bd",
   "metadata": {},
   "source": [
    "## File imports and settings\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "baf46e0c-4be5-4964-9079-78af0bc5884d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "###This is for Windows users...python will default to only using \"E\" cores\n",
    "desired_cpus = list(range(20))  # CPUs 0 through 11\n",
    "\n",
    "\n",
    "p = psutil.Process(os.getpid())\n",
    "\n",
    "\n",
    "p.cpu_affinity(desired_cpus)\n",
    "\n",
    "print(\"CPU affinity set to:\", p.cpu_affinity())\n",
    "#from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "#import psutil\n",
    "import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ### this hides some of the annoying tflow errors\n",
    "#### this depends on the hardware\n",
    "from pathlib import Path ####Required for save checks\n",
    "import prince ####Required for MCA functions\n",
    "\n",
    "import j_process ####Required to load custom modeling functions\n",
    "import j_clustertuner####Required for best K functions\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "skip = False\n",
    "subset=False\n",
    "redundant=False"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63cb4232-682f-4170-a7e4-59a10264d75b",
   "metadata": {},
   "source": "df = pd.read_parquet(\"data/filtered.parquet\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7d86b607-f8e9-4b7e-a463-abf94b8f64f8",
   "metadata": {},
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce7239e2-fbab-47b0-89c2-3edd26b3a993",
   "metadata": {},
   "source": [
    "#Just a function to help me visualize each feature\n",
    "\n",
    "def i_graph(colname):\n",
    "    ig_counts = df[colname].value_counts(dropna=False)\n",
    "    \n",
    "    print(\"Value counts for\", colname)\n",
    "    print(ig_counts)\n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f256c056-d1aa-4c3f-b5c2-f95a26a9dde7",
   "metadata": {},
   "source": [
    "def repval(colname, stringstorepl):\n",
    "    df[colname] = df[colname].replace(stringstorepl,np.nan)\n",
    "    rg_counts = df[colname].value_counts(dropna=False)\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "26aba1efc701ffac",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "def basic_plot(colname):\n",
    "    rg_counts = df[colname].value_counts(dropna=False)\n",
    "    rg_ax = rg_counts.plot(kind='bar')\n",
    "    plt.title('Counts per Category')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    for i, v in enumerate(rg_counts):\n",
    "        rg_ax.text(i, v + max(rg_counts) * 0.01, str(v), ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Ensure the images directory exists\n",
    "    os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "    rg_title = colname\n",
    "    rg_filename = rg_title.replace(\" \", \"_\").replace(\"/\", \"-\") + \".jpg\"\n",
    "    filepath = os.path.join(\"images\", rg_filename)\n",
    "\n",
    "    plt.savefig(filepath, format='jpg', dpi=300)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "75612ea8-4fa7-4030-9964-11d6f4aef16e",
   "metadata": {},
   "source": [
    "## Cleaned up variables"
   ]
  },
  {
   "cell_type": "code",
   "id": "2daa745a-fd2c-4405-b506-bae1509f713c",
   "metadata": {},
   "source": [
    "default = [\"Don't know/Not sure\",\"Refused\",\"Missing\",\"Don't know / Not sure\",\"Don't know/Not Sure\"]\n",
    "repval(\"CVDINFR4\", [\"Don't know/Not sure\", \"Refused\", \"Missing\"])\n",
    "repval(\"CVDCRHD4\", [\"Don't know/Not sure\", \"Refused\", \"Missing\"])\n",
    "repval(\"CVDSTRK3\", default)\n",
    "df[\"ASTHMA3\"] = df[\"ASTHMA3\"].replace([\"No -  Go to Section 07.06 CHCSCNC1\"], \"No\")\n",
    "repval(\"ASTHMA3\",\n",
    "       [\"Don't know/Not Sure -  Go to Section 07.06 CHCSCNC1\", \"Refused -  Go to Section 07.06 CHCSCNC1\", \"Missing\"])\n",
    "repval(\"CHCSCNC1\", default)\n",
    "repval(\"CHCOCNC1\", default)\n",
    "repval(\"CHCCOPD3\", default)\n",
    "repval(\"CHCKDNY2\", default)\n",
    "repval(\"HAVARTH4\", default)\n",
    "df[\"DIABETE4\"]=df[\"DIABETE4\"].replace([\"No -  Go to Section 08.01 AGE\"],\"No\")\n",
    "repval(\"DIABETE4\", [\"No, pre-diabetes or borderline diabetes -  Go to Section 08.01 AGE\", \"Yes, but female told only during pregnancy -  Go to Section 08.01 AGE\", \"Don't know/Not Sure -  Go to Section 08.01 AGE\", \"Refused -  Go to Section 08.01 AGE\"])\n",
    "df[\"EDUCA\"]=df[\"EDUCA\"].replace([\"College 4 years or more (College graduate)\"],\"Bachelors degree or Higher\")\n",
    "df[\"EDUCA\"]=df[\"EDUCA\"].replace([\"College 1 year to 3 years (Some college or technical school)\"],\"Some College or Associates\")\n",
    "df[\"EDUCA\"]=df[\"EDUCA\"].replace([\"Grade 12 or GED (High school graduate)\"],\"High School Graduate\")\n",
    "df[\"EDUCA\"]=df[\"EDUCA\"].replace([\"Grades 9 through 11 (Some high school)\"],\"Some High School\")\n",
    "df[\"EDUCA\"]=df[\"EDUCA\"].replace([\"Grades 1 through 8 (Elementary)\"],\"Elementary Only\")\n",
    "df[\"EDUCA\"]=df[\"EDUCA\"].replace([\"Never attended school or only kindergarten\"],\"None or Kindergarten Only\")\n",
    "repval(\"EDUCA\", default)\n",
    "repval(\"DEAF\", default)\n",
    "repval(\"BLIND\", default)\n",
    "repval(\"DECIDE\", default)\n",
    "repval(\"DIFFWALK\", default)\n",
    "repval(\"DIFFDRES\", default)\n",
    "repval(\"DIFFALON\", default)\n",
    "df[\"SMOKE100\"]=df[\"SMOKE100\"].replace([\"No -  Go to Section 12.03 USENOW3\"],\"No\")\n",
    "df[\"SMOKE100\"]=df[\"SMOKE100\"].replace([\"Don't know/Not Sure -  Go to Section 12.03 USENOW3\"],\"Don't know/Not Sure\")\n",
    "df[\"SMOKE100\"]=df[\"SMOKE100\"].replace([\"Refused -  Go to Section 12.03 USENOW3\"],\"Refused\")\n",
    "repval(\"SMOKE100\", default)\n",
    "df[\"ECIGNOW2\"]=df[\"ECIGNOW2\"].replace([\"Never used e-cigarettes in your entire life\"],\"Never\")\n",
    "df[\"ECIGNOW2\"]=df[\"ECIGNOW2\"].replace([\"Not at all (right now)\"],\"Not Currently\")\n",
    "df[\"ECIGNOW2\"]=df[\"ECIGNOW2\"].replace([\"Use them some days\"],\"Some Days\")\n",
    "df[\"ECIGNOW2\"]=df[\"ECIGNOW2\"].replace([\"Use them every day\"],\"Every Day\")\n",
    "df[\"FLUSHOT7\"]=df[\"FLUSHOT7\"].replace([\"No -  Go to Section 13.03 PNEUVAC4\"],\"No\")\n",
    "df[\"FLUSHOT7\"]=df[\"FLUSHOT7\"].replace([\"Don't know/Not Sure -  Go to Section 13.03 PNEUVAC4\"],\"Don't know/Not sure\")\n",
    "df[\"FLUSHOT7\"]=df[\"FLUSHOT7\"].replace([\"Refused -  Go to Section 13.03 PNEUVAC4\"],\"Refused\")\n",
    "repval(\"ECIGNOW2\", default)\n",
    "repval(\"FLUSHOT7\", default)\n",
    "repval(\"PNEUVAC4\", default)\n",
    "df[\"SEATBELT\"]=df[\"SEATBELT\"].replace([\"Never drive or ride in a car -  Go to Section 16.1 COVIDPO1\"],\"Refused\")\n",
    "\n",
    "repval(\"SEATBELT\", default)\n",
    "df[\"COVIDPO1\"]=df[\"COVIDPO1\"].replace([\"No -  Go to Modules or Closing Statement\"],\"No\")\n",
    "df[\"COVIDPO1\"]=df[\"COVIDPO1\"].replace([\"Refused -  Go to Modules or Closing Statement\"],\"Refused\")\n",
    "df[\"COVIDPO1\"]=df[\"COVIDPO1\"].replace([\"Don't know/Not Sure -  Go to Modules or Closing Statement\"],\"Don't know/Not sure\")\n",
    "\n",
    "repval(\"COVIDPO1\", default)\n",
    "repval(\"GENHLTH\", default)\n",
    "df[\"EXERANY2\"]=df[\"EXERANY2\"].replace([\"No -  Go to Section 04.08 STRENGTH\"],\"No\")\n",
    "df[\"EXERANY2\"]=df[\"EXERANY2\"].replace([\"Don't know/Not Sure -  Go to Section 04.08 STRENGTH\"],\"Don't know/Not sure\")\n",
    "df[\"EXERANY2\"]=df[\"EXERANY2\"].replace([\"Refused -  Go to Section 04.08 STRENGTH\"],\"Refused\")\n",
    "\n",
    "repval(\"EXERANY2\", default)\n",
    "repval(\"TOLDHI3\", default)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "03443526-cff4-4043-8b79-a1aee1de0301",
   "metadata": {},
   "source": [
    "j_process.resp_tally2(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9642b0e-7b3f-45a2-8853-5b03046d09f9",
   "metadata": {},
   "source": [
    "print(df.isna().sum())\n",
    "print(df.shape)\n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "571b3a8d-ae58-4637-b7d9-5a306b5c0220",
   "metadata": {},
   "source": [
    "columns_to_check = ['CVDINFR4', 'CVDCRHD4', 'CVDSTRK3','ASTHMA3','CHCSCNC1','CHCOCNC1','CHCCOPD3','CHCKDNY2','HAVARTH4','DIABETE4']\n",
    "chronic_col = columns_to_check\n",
    "df['ALL_CHRONIC'] = df[columns_to_check].eq('Yes').any(axis=1).map({True: 'Yes', False: 'No'})\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Derived target variable information",
   "id": "509a848811e4eed6"
  },
  {
   "cell_type": "code",
   "id": "3f5e4845-4740-49ec-b9df-414b3a1d1c37",
   "metadata": {},
   "source": [
    "df['ALL_CHRONIC'].value_counts(dropna=False)\n",
    "df['ALL_CHRONIC'].value_counts().plot(kind='bar')\n",
    "plt.title('Any Chronic Condition')\n",
    "plt.xlabel('Response')\n",
    "plt.ylabel('Count')\n",
    "title = plt.gca().get_title()\n",
    "filename = title.replace(\" \", \"_\").replace(\"/\", \"-\") + \".jpg\"\n",
    "filename = os.path.join(\"images\",filename)\n",
    "plt.savefig(filename, format='jpg', dpi=300)\n",
    "plt.show()\n",
    "df['ALL_CHRONIC'].value_counts(normalize=True, dropna=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6998658b-fb48-4cc0-9ec4-1cc89ab81c64",
   "metadata": {},
   "source": [
    "columns_to_check = ['CVDINFR4', 'CVDCRHD4', 'CVDSTRK3','ASTHMA3','CHCSCNC1','CHCOCNC1','CHCCOPD3','CHCKDNY2','DIABETE4']\n",
    "\n",
    "df['ALL_CHRONIC2'] = df[columns_to_check].eq('Yes').any(axis=1).map({True: 'Yes', False: 'No'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "64a3d20a-244e-4612-a8ae-d9b1a04a0266",
   "metadata": {},
   "source": [
    "columns_to_check = ['CVDINFR4', 'CVDCRHD4', 'CVDSTRK3']\n",
    "\n",
    "df['ALL_CARDIAC'] = df[columns_to_check].eq('Yes').any(axis=1).map({True: 'Yes', False: 'No'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6325800e-6660-407c-bf46-992ae1536089",
   "metadata": {},
   "source": [
    "df['ALL_CHRONIC2'].value_counts(dropna=False)\n",
    "df['ALL_CHRONIC2'].value_counts().plot(kind='bar')\n",
    "plt.title('Any Chronic (alt) Condition')\n",
    "plt.xlabel('Response')\n",
    "plt.ylabel('Count')\n",
    "title = plt.gca().get_title()\n",
    "filename = title.replace(\" \", \"_\").replace(\"/\", \"-\") + \".jpg\"\n",
    "filename = os.path.join(\"images\",filename)\n",
    "plt.savefig(filename, format='jpg', dpi=300)\n",
    "plt.show()\n",
    "df['ALL_CHRONIC2'].value_counts(normalize=True, dropna=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "da4b4a1c-7721-4d9b-9349-c835619d99b4",
   "metadata": {},
   "source": [
    "df['ALL_CARDIAC'].value_counts(dropna=False)\n",
    "df['ALL_CARDIAC'].value_counts().plot(kind='bar')\n",
    "plt.title('Any Cardiac Condition')\n",
    "plt.xlabel('Response')\n",
    "plt.ylabel('Count')\n",
    "title = plt.gca().get_title()\n",
    "filename = title.replace(\" \", \"_\").replace(\"/\", \"-\") + \".jpg\"\n",
    "filename = os.path.join(\"images\",filename)\n",
    "plt.savefig(filename, format='jpg', dpi=300)\n",
    "plt.show()\n",
    "df['ALL_CARDIAC'].value_counts(normalize=True, dropna=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ee57840-a255-459c-a40b-5fab25b2c67e",
   "metadata": {},
   "source": [
    "columns_to_check = ['CHCSCNC1','CHCOCNC1']\n",
    "\n",
    "df['ALL_CANCER'] = df[columns_to_check].eq('Yes').any(axis=1).map({True: 'Yes', False: 'No'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6ddc9553-f0bc-4fce-9a76-fc73bd3ed5f1",
   "metadata": {},
   "source": [
    "df['ALL_CANCER'].value_counts(dropna=False)\n",
    "df['ALL_CANCER'].value_counts().plot(kind='bar')\n",
    "plt.title('Any Cancer Response')\n",
    "plt.xlabel('Response')\n",
    "plt.ylabel('Count')\n",
    "title = plt.gca().get_title()\n",
    "filename = title.replace(\" \", \"_\").replace(\"/\", \"-\") + \".jpg\"\n",
    "filename = os.path.join(\"images\",filename)\n",
    "plt.savefig(filename, format='jpg', dpi=300)\n",
    "plt.show()\n",
    "df['ALL_CANCER'].value_counts(normalize=True, dropna=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c05c5253-dd48-4978-bd31-9490794b45d4",
   "metadata": {},
   "source": [
    "columns_to_check = ['ASTHMA3','CHCCOPD3']\n",
    "\n",
    "df['ALL_PUL'] = df[columns_to_check].eq('Yes').any(axis=1).map({True: 'Yes', False: 'No'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7d013c55-2f19-4760-a842-a52108bc74fc",
   "metadata": {},
   "source": [
    "df['ALL_PUL'].value_counts(dropna=False)\n",
    "df['ALL_PUL'].value_counts().plot(kind='bar')\n",
    "plt.title('Any Pulmonary Response')\n",
    "plt.xlabel('Response')\n",
    "plt.ylabel('Count')\n",
    "title = plt.gca().get_title()\n",
    "filename = title.replace(\" \", \"_\").replace(\"/\", \"-\") + \".jpg\"\n",
    "filename = os.path.join(\"images\",filename)\n",
    "plt.savefig(filename, format='jpg', dpi=300)\n",
    "plt.show()\n",
    "df['ALL_PUL'].value_counts(normalize=True, dropna=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Chronic target statistics",
   "id": "19278dfcf3813e4e"
  },
  {
   "cell_type": "code",
   "id": "7f5cf39b-ecc5-4056-b12c-c7b3235e6991",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "columns_to_check = [\n",
    "    'CVDINFR4', 'CVDCRHD4', 'CVDSTRK3',\n",
    "    'ASTHMA3', 'CHCSCNC1', 'CHCOCNC1',\n",
    "    'CHCCOPD3', 'CHCKDNY2', 'HAVARTH4', 'DIABETE4'\n",
    "]\n",
    "yes_rates = {\n",
    "    col: (df[col] == \"Yes\").mean() * 100  \n",
    "    for col in columns_to_check\n",
    "}\n",
    "\n",
    "\n",
    "yes_df = pd.Series(yes_rates).sort_values(ascending=False)\n",
    "\n",
    "ax = yes_df.plot(kind='bar')\n",
    "plt.title('Percentage of Yes Responses by Condition')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.xlabel('Condition')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "title = plt.gca().get_title()\n",
    "filename = title.replace(\" \", \"_\").replace(\"/\", \"-\") + \".jpg\"\n",
    "filename = os.path.join(\"images\",filename)\n",
    "plt.savefig(filename, format='jpg', dpi=300)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "02802ef2-c158-4849-a82c-4a01d989552a",
   "metadata": {},
   "source": [
    "column_list = df.columns.tolist()\n",
    "print(column_list)\n",
    "feature_list = [col for col in column_list if col not in chronic_col]\n",
    "deriv_col = ['ALL_CHRONIC','ALL_CARDIAC','ALL_CANCER','ALL_PUL','ALL_CHRONIC2']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fea57710-8838-461d-8476-295873cbbd45",
   "metadata": {},
   "source": [
    "feature_list = [col for col in feature_list if col not in deriv_col]\n",
    "print(feature_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "383cef46-6c8d-4fca-bf50-fc7cf11109ce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "for col in feature_list:\n",
    "    counts = df[col].value_counts(dropna=False)\n",
    "\n",
    "    # Print counts for reference\n",
    "    print(f\"\\nValue counts for {col}:\\n{counts}\")\n",
    "\n",
    "    # Plot\n",
    "    ax = counts.plot(kind='bar')\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel('Response')\n",
    "    plt.ylabel('Count')\n",
    "    title = plt.gca().get_title()\n",
    "    filename = title.replace(\" \", \"_\").replace(\"/\", \"-\") + \".jpg\"\n",
    "    filename = os.path.join(\"images\",filename)\n",
    "    plt.savefig(filename, format='jpg', dpi=300)\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7729234a-2fd2-49a4-8452-0e2968846275",
   "metadata": {},
   "source": [
    "bool_feat = ['DEAF', 'BLIND', 'DECIDE', 'DIFFWALK', 'DIFFDRES',\n",
    "              'DIFFALON', 'SMOKE100', 'FLUSHOT7', 'PNEUVAC4',\n",
    "               'COVIDPO1', 'EXERANY2', 'TOLDHI3']\n",
    "cat_feat=['GENHLTH', 'SEATBELT','ECIGNOW2','EDUCA']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c24eb7e9-9440-4e02-a731-e17cad3f0402",
   "metadata": {},
   "source": [
    "lifestyle_factors = bool_feat  \n",
    "heat_data = {}\n",
    "\n",
    "for col in lifestyle_factors:\n",
    "    yes_rate = df[df[col] == 'Yes']['ALL_CHRONIC'].value_counts(normalize=True)\n",
    "    heat_data[col] = yes_rate\n",
    "\n",
    "heat_df = pd.DataFrame(heat_data).T.fillna(0)\n",
    "\n",
    "sns.heatmap(heat_df, annot=True, cmap='Blues')\n",
    "plt.title(\"Chronic Condition Rates Among Respondents With Each Reported Risk Factor\")\n",
    "plt.ylabel(\"Risk Factor\")\n",
    "plt.xlabel(\"Chronic Condition\")\n",
    "plt.tight_layout()\n",
    "filename=\"chronic_condition_heatmap.jpg\"\n",
    "filename = os.path.join(\"images\",filename)\n",
    "plt.savefig(filename, format='jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c97c0327-4d92-4bea-b0c7-f81977383e14",
   "metadata": {},
   "source": [
    "heat_data = {}\n",
    "\n",
    "for col in lifestyle_factors:\n",
    "    yes_rate = df[df[col] == 'Yes']['ALL_CHRONIC2'].value_counts(normalize=True)\n",
    "    heat_data[col] = yes_rate\n",
    "\n",
    "heat_df = pd.DataFrame(heat_data).T.fillna(0)\n",
    "\n",
    "sns.heatmap(heat_df, annot=True, cmap='Blues')\n",
    "plt.title(\"Chronic2 Condition Rates Among Respondents With Each Reported Risk Factor\")\n",
    "plt.ylabel(\"Risk Factor\")\n",
    "plt.xlabel(\"Chronic Condition\")\n",
    "plt.tight_layout()\n",
    "filename=\"chronic2_condition_heatmap.jpg\"\n",
    "filename = os.path.join(\"images\",filename)\n",
    "plt.savefig(filename, format='jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "490c3b00-48ee-44bd-a54d-327ca4fd3b44",
   "metadata": {},
   "source": [
    "heat_data={}\n",
    "for col in lifestyle_factors:\n",
    "    yes_rate = df[df[col] == 'No']['ALL_CHRONIC'].value_counts(normalize=True)\n",
    "    heat_data[col] = yes_rate\n",
    "\n",
    "heat_df = pd.DataFrame(heat_data).T.fillna(0)\n",
    "heat_df = heat_df[['Yes', 'No']]\n",
    "sns.heatmap(heat_df, annot=True, cmap='Blues')\n",
    "plt.title(\"Chronic Condition Rates Among Respondents Without Each Reported Risk Factor\")\n",
    "plt.ylabel(\"Risk Factor\")\n",
    "plt.xlabel(\"Chronic Condition\")\n",
    "plt.tight_layout()\n",
    "filename=\"neg_chronic_condition_heatmap.jpg\"\n",
    "filename = os.path.join(\"images\",filename)\n",
    "plt.savefig(filename, format='jpg', dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "76f8b14b-05a3-4bb5-a090-2e3d4cf8fb1b",
   "metadata": {},
   "source": [
    "#######USED IN EDA#####\n",
    "\n",
    "edu_chronic = df.groupby('EDUCA')['ALL_CHRONIC'].value_counts(normalize=True).unstack().fillna(0)\n",
    "ordered_levels = [\"Bachelors degree or Higher\",\"Some College or Associates\", \"High School Graduate\", \"Elementary Only\", \"None or Kindergarten Only\"]\n",
    "edu_chronic = edu_chronic.loc[ordered_levels]\n",
    "\n",
    "edu_chronic.plot(kind='bar', stacked=True)\n",
    "plt.title('Chronic Condition Distribution by Education Level')\n",
    "plt.xlabel('Education Level')\n",
    "plt.ylabel('Proportion')\n",
    "plt.legend(title='Has Chronic Condition')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "filename =\"educationvschronic.jpg\"\n",
    "filename = os.path.join(\"images\",filename)\n",
    "\n",
    "plt.savefig(filename, format='jpg', dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "046954a2-2584-43f8-9147-e8dcb7ca5571",
   "metadata": {},
   "source": [
    "##### USED IN EDA#####\n",
    "\n",
    "features = ['ECIGNOW2', 'SEATBELT', 'GENHLTH']\n",
    "\n",
    "# Friendly labels for x-axis\n",
    "x_labels = {\n",
    "    'ECIGNOW2': 'E-Cigarette Use',\n",
    "    'SEATBELT': 'Seatbelt Use Frequency',\n",
    "    'GENHLTH': 'General Health'\n",
    "}\n",
    "\n",
    "#Fix the order of the labels\n",
    "category_orders = {\n",
    "    'ECIGNOW2': ['Every Day', 'Some Days', 'Not Currently', 'Never'],  \n",
    "    'SEATBELT': ['Always', 'Nearly always', 'Sometimes', 'Seldom', 'Never'],\n",
    "    'GENHLTH': ['Excellent', 'Very good', 'Good', 'Fair', 'Poor']\n",
    "}\n",
    "\n",
    "for col in features:\n",
    "\n",
    "    ctab = pd.crosstab(df[col], df['ALL_CHRONIC'], normalize='index').fillna(0)\n",
    "    if col in category_orders:\n",
    "        ctab = ctab.reindex(category_orders[col])\n",
    "    ax = ctab.plot(kind='bar', stacked=True, figsize=(8, 4))\n",
    "    plt.title(f'Chronic Condition Distribution by {x_labels[col]}')\n",
    "    plt.xlabel(x_labels[col])\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.legend(title='Has Chronic Condition')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = f\"chronic_vs_{col}.jpg\".replace(\" \", \"_\").lower()\n",
    "    filename = os.path.join(\"images\",filename)\n",
    "\n",
    "    plt.savefig(filename, format='jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "54cab0e7-09c5-425e-af50-f759e01ba0f7",
   "metadata": {},
   "source": [
    "####Check to see if the filtered data was saved\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = Path(\"data/rq3_filtered.parquet\")\n",
    "if file_path.exists():\n",
    "    print(\"File exists.\")\n",
    "else:\n",
    "    print(\"File not found.\")\n",
    "    df.to_parquet(\n",
    "        \"rq3_filtered.parquet\",\n",
    "        engine=\"pyarrow\",\n",
    "        compression=\"BROTLI\",\n",
    "        compression_level=11,\n",
    "        index=False\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['ALL_CARDIAC'].value_counts()",
   "id": "cc0ad8af452d95aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if subset==True:\n",
    "    df_yes=df[df['ALL_CHRONIC2']=='Yes']\n",
    "    df_no=df[df['ALL_CHRONIC2']=='No']\n",
    "    df_no=df_no.sample(n=len(df_yes),random_state=42)\n",
    "    df=pd.concat([df_yes,df_no])\n",
    "else:\n",
    "    print(\"skipping subsample...\")"
   ],
   "id": "544e03ffe1703444",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(df['ALL_CARDIAC'].value_counts())\n",
    "print(df['ALL_CHRONIC2'].value_counts())\n",
    "print(df['ALL_CHRONIC'].value_counts())\n",
    "print(df['ALL_PUL'].value_counts())\n"
   ],
   "id": "e3748b03395ec8eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c968290-fec3-4e68-9d62-3dfef7ca878b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "df_val, df_train = train_test_split(\n",
    "    df, test_size=0.70, random_state=42, stratify=df[\"ALL_CHRONIC2\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Validation shape: {df_val.shape}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "158b82ff-e32b-4987-b22c-bb312f9a6a7b",
   "metadata": {},
   "source": [
    "Testing for optimal Kmode Clusters"
   ]
  },
  {
   "cell_type": "code",
   "id": "618f0e5e-212d-499f-9fde-df8131fdb0d3",
   "metadata": {},
   "source": [
    "#### Check to see if KMODE clustering cost results are available\n",
    "#### Will take a long time to rerun, download \"rq3_all_kresults.parquet\" to skip\n",
    "\n",
    "file_path = Path(\"data/rq3_all_kresults.parquet\")\n",
    "if file_path.exists():\n",
    "    print(\"File exists.\")\n",
    "    all_kresults = pd.read_parquet(file_path)\n",
    "    print(all_kresults.head())\n",
    "    \n",
    "else:\n",
    "    print(\"Save not found, running tuner...May take a while...\")\n",
    "    all_kresults = j_clustertuner.kmode_tune(df_val,feature_list,n_cluster=256,n_trials=10,cores=15)\n",
    "    j_process.save_if_changed(all_kresults,\"data/rq3_all_kresults.parquet\")\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "45240679-fd26-427e-b5a0-b493f4a1cbd3",
   "metadata": {},
   "source": [
    "j_clustertuner.plot_kmode_elbow(all_kresults)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b2ee2e07-0b2b-420d-b814-a7abbf391d82",
   "metadata": {},
   "source": [
    "Test for Optimal TFlow number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "id": "4e1185fa-9da5-4c5d-8fb3-4933b8f297c1",
   "metadata": {},
   "source": [
    "#####Check to see if silhouette score data is available. \n",
    "#####Will take a long time ot rerun, make sure \"rq3_all_tresults.parquet\" is present\n",
    "\n",
    "file_path = Path(\"data/rq3_all_tresults.parquet\")\n",
    "if file_path.exists():\n",
    "    print(\"File exists.Loading file.\")\n",
    "    all_tresults = pd.read_parquet(file_path)\n",
    "    print(all_tresults.head())\n",
    "\n",
    "else:\n",
    "    print(\"Save not found, running tuner...May take a while...\")\n",
    "    \n",
    "\n",
    "    all_tresults = j_clustertuner.tflow_tune(df_test,df_val,feature_list)\n",
    "    j_process.save_if_changed(all_tresults,\"data/rq3_all_tresults.parquet\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b6cdee0-9d7b-4c8b-a4f9-ad0bee63aaac",
   "metadata": {},
   "source": [
    "\n",
    "j_clustertuner.analyze_silhouette_scores(all_tresults)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d9e48506-09be-4b28-8656-a7ed847d7539",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "\n",
    "# Ensure both are lists, then combine\n",
    "bool_feat = list(bool_feat)\n",
    "cat_feat = list(cat_feat)\n",
    "combined_feat = bool_feat + cat_feat\n",
    "\n",
    "# Drop the combined features from df\n",
    "#mca_set = df_train.drop(columns=combined_feat, inplace=False)\n",
    "#mca_valset = df_val.drop(columns=combined_feat,inplace=False)\n",
    "mca_set = df_train.copy()\n",
    "mca_set = mca_set[combined_feat]\n",
    "mca_val = df_val.copy()\n",
    "mca_val = mca_val[combined_feat]\n",
    "\n",
    "\n",
    "\n",
    "mca = prince.MCA( n_components=27,random_state=42)\n",
    "mca = mca.fit(mca_set)\n",
    "\n",
    "X_reduced = mca.transform(mca_set)\n",
    "#X_reduced.shape\n",
    "\n",
    "#explained = mca.explained_inertia_\n",
    "eigen = mca.eigenvalues_\n",
    "total = mca.total_inertia_\n",
    "explained = eigen / total\n",
    "#print(explained)\n",
    "\n",
    "\n",
    "cumulative = np.cumsum(explained)\n",
    "\n",
    "plt.plot(range(1, len(cumulative)+1), cumulative, marker='o')\n",
    "plt.axhline(y=0.8, color='r', linestyle='--', label='80% threshold')\n",
    "plt.title(\"Cumulative Explained Inertia (MCA)\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Inertia\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(\"images/mca_inertia.jpg\", format='jpg', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Find minimum number of components to reach 80%\n",
    "\n",
    "k = np.argmax(cumulative >= 0.80) + 1\n",
    "print(f\"Components to reach 80% inertia: {k}\")\n",
    "k=np.argmax(cumulative>=.95) +1\n",
    "print(f\"Max intertia at: {k}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2d882f37-533e-488c-98fe-719b95a6291c",
   "metadata": {},
   "source": [
    "plt.plot(range(1, len(explained)+1), explained, marker='o')\n",
    "plt.title(\"Scree Plot (Explained Inertia per Component)\")\n",
    "plt.xlabel(\"Component\")\n",
    "plt.ylabel(\"Explained Inertia\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"images/screeplot_mca.jpg\", format='jpg', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "77abb654-07fc-4677-8ba9-f117d28ab913",
   "metadata": {},
   "source": [
    "mca = prince.MCA(n_components=2, random_state=42)\n",
    "mca = mca.fit(df_train)\n",
    "\n",
    "if skip == True:\n",
    "    print(\"skipping\")\n",
    "else:\n",
    "    mca_row_coords = mca.row_coordinates(df_train)\n",
    "    plt.scatter(mca_row_coords[0], mca_row_coords[1], alpha=0.5)\n",
    "    plt.title(\"Individuals Factorial Plane (Dim 1 vs Dim 2)\")\n",
    "    plt.xlabel(\"Dim 1\")\n",
    "    plt.ylabel(\"Dim 2\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # For variables\n",
    "    mca_col_coords = mca.column_coordinates(df_train)\n",
    "    plt.scatter(mca_col_coords[0], mca_col_coords[1])\n",
    "    plt.title(\"Variable Factorial Plane (Dim 1 vs Dim 2)\")\n",
    "    plt.xlabel(\"Dim 1\")\n",
    "    plt.ylabel(\"Dim 2\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    cos2 = (mca_col_coords ** 2).div((mca_col_coords ** 2).sum(axis=1), axis=0)\n",
    "    cos2.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5902e879-7c8d-4fed-9dd2-109c02c0d3ee",
   "metadata": {},
   "source": [
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "####future: save ram and clean this up\n",
    "\n",
    "###create model datasets\n",
    "\n",
    "####Raw set\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_rawtrain = df_train.copy()\n",
    "df_rawval = df_val.copy()\n",
    "\n",
    "\n",
    "###Kmodes\n",
    "km_train = df_train.copy()\n",
    "km_val = df_val.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###Cluster\n",
    "mc_train=df_train.copy()\n",
    "mc_val=df_val.copy()\n"
   ],
   "id": "589d02e7-5dc0-463c-98b2-6c1bc3c2f973",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a61bb5a4-79d9-4a07-b4fa-f2c08bb826de",
   "metadata": {},
   "source": [
    "## Baseline and Feature Importance Results\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d149ee3d-9077-4d47-ac6a-1d7b44edcd91",
   "metadata": {},
   "source": [
    "\n",
    "# Your targets\n",
    "target_labels = [\"ALL_CHRONIC\", \"ALL_CARDIAC\", \"ALL_PUL\", \"ALL_CHRONIC2\"]\n",
    "\n",
    "# Run all models in parallel\n",
    "baseline_scores = Parallel(n_jobs=4)(\n",
    "    delayed(j_process.run_logistic_model)(\n",
    "        df_rawtrain,\n",
    "        df_rawval,\n",
    "        feature_list,\n",
    "        target,\n",
    "        plot_importance=True,\n",
    "        importance_filename=f\"images/{target.lower()}_importance.jpg\"\n",
    "    )\n",
    "    for target in target_labels\n",
    ")\n",
    "\n",
    "\n",
    "all_chronic_scores, all_cardiac_scores, all_pul_scores, all_chronic2_scores = baseline_scores\n",
    "print(baseline_scores)\n",
    "df_scores = pd.DataFrame(baseline_scores, index=target_labels)\n",
    "\n",
    "\n",
    "# Convert metrics to percent and round to 3 decimals\n",
    "df_percent = df_scores.copy() * 100\n",
    "df_percent = df_percent.round(3)\n",
    "\n",
    "# Reset index to make target names a column\n",
    "df_percent.insert(0, \"Target\", df_percent.index)\n",
    "\n",
    "# Plot as a table\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "table = ax.table(\n",
    "    cellText=df_percent.values,\n",
    "    colLabels=df_percent.columns,\n",
    "    cellLoc='center',\n",
    "    loc='center'\n",
    ")\n",
    "\n",
    "# Add a title\n",
    "ax.set_title(\"Baseline Model Performance Metrics (%)\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/baseline_scores_table.jpg\", dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "727153f6-0f47-4b09-8174-45fe7e16da31",
   "metadata": {},
   "source": [
    "### Logistic Scores"
   ]
  },
  {
   "cell_type": "code",
   "id": "1a575ea3-8df9-40e3-ac55-650e23c62119",
   "metadata": {},
   "source": [
    "def summarize_model_results(name, score_dict):\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Accuracy': score_dict.get('accuracy'),\n",
    "        'Precision': score_dict.get('precision'),\n",
    "        'Recall': score_dict.get('recall'),\n",
    "        'F1 Score': score_dict.get('f1_score')\n",
    "    }\n",
    "\n",
    "summary_df = pd.DataFrame([\n",
    "    summarize_model_results('ALL_CHRONIC', all_chronic_scores),\n",
    "    summarize_model_results('ALL_CARDIAC', all_cardiac_scores),\n",
    "    summarize_model_results('ALL_PUL', all_pul_scores),\n",
    "    summarize_model_results('ALL_CHRONIC2', all_chronic2_scores)\n",
    "])\n",
    "\n",
    "\n",
    "print(summary_df)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9fb0b7f4-35b9-4ec2-b878-2342f785ed1c",
   "metadata": {},
   "source": [
    "all_chronic_results_dict={}\n",
    "all_cardiac_results_dict={}\n",
    "all_pul_results_dict={}\n",
    "all_chronic2_results_dict={}\n",
    "for feature in feature_list:\n",
    "    #print(f\"\\n---Running baseline on feature:{feature}---\")\n",
    "    results = j_process.run_logistic_model(df_rawtrain,df_rawval,[feature],\"ALL_CHRONIC\")\n",
    "    all_chronic_results_dict[feature]=results\n",
    "\n",
    "for feature in feature_list:\n",
    "    #print(f\"\\n---Running baseline on feature:{feature}---\")\n",
    "    results = j_process.run_logistic_model(df_rawtrain,df_rawval,[feature],\"ALL_CARDIAC\")\n",
    "    all_cardiac_results_dict[feature]=results\n",
    "\n",
    "for feature in feature_list:\n",
    "    #print(f\"\\n---Running baseline on feature:{feature}---\")\n",
    "    results = j_process.run_logistic_model(df_rawtrain,df_rawval,[feature],\"ALL_PUL\")\n",
    "    all_pul_results_dict[feature]=results\n",
    "for feature in feature_list:\n",
    "    #print(f\"\\n---Running baseline on feature:{feature}---\")\n",
    "    results = j_process.run_logistic_model(df_rawtrain,df_rawval,[feature],\"ALL_CHRONIC2\")\n",
    "    all_chronic2_results_dict[feature]=results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- ALL_CHRONIC ---\n",
    "df_all_chronic = pd.DataFrame.from_dict(all_chronic_results_dict, orient='index') * 100\n",
    "df_all_chronic = df_all_chronic.round(3)\n",
    "df_all_chronic.index.name = 'Feature'\n",
    "df_all_chronic.reset_index(inplace=True)\n",
    "display(df_all_chronic)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, len(df_all_chronic) * 0.35))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "table = ax.table(cellText=df_all_chronic.values,\n",
    "                 colLabels=df_all_chronic.columns,\n",
    "                 cellLoc='center',\n",
    "                 loc='center')\n",
    "ax.set_title(\"ALL_CHRONIC: Single-Feature Logistic Regression Results (%)\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/all_chronic_results.jpg\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- ALL_CARDIAC ---\n",
    "df_all_cardiac = pd.DataFrame.from_dict(all_cardiac_results_dict, orient='index') * 100\n",
    "df_all_cardiac = df_all_cardiac.round(3)\n",
    "df_all_cardiac.index.name = 'Feature'\n",
    "df_all_cardiac.reset_index(inplace=True)\n",
    "display(df_all_cardiac)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, len(df_all_cardiac) * 0.35))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "table = ax.table(cellText=df_all_cardiac.values,\n",
    "                 colLabels=df_all_cardiac.columns,\n",
    "                 cellLoc='center',\n",
    "                 loc='center')\n",
    "ax.set_title(\"ALL_CARDIAC: Single-Feature Logistic Regression Results (%)\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/all_cardiac_results.jpg\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- ALL_PUL ---\n",
    "df_all_pul = pd.DataFrame.from_dict(all_pul_results_dict, orient='index') * 100\n",
    "df_all_pul = df_all_pul.round(3)\n",
    "df_all_pul.index.name = 'Feature'\n",
    "df_all_pul.reset_index(inplace=True)\n",
    "display(df_all_pul)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, len(df_all_pul) * 0.35))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "table = ax.table(cellText=df_all_pul.values,\n",
    "                 colLabels=df_all_pul.columns,\n",
    "                 cellLoc='center',\n",
    "                 loc='center')\n",
    "ax.set_title(\"ALL_PUL: Single-Feature Logistic Regression Results (%)\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/all_pul_results.jpg\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- ALL_CHRONIC2 ---\n",
    "df_all_chronic2 = pd.DataFrame.from_dict(all_chronic2_results_dict, orient='index') * 100\n",
    "df_all_chronic2 = df_all_chronic2.round(3)\n",
    "df_all_chronic2.index.name = 'Feature'\n",
    "df_all_chronic2.reset_index(inplace=True)\n",
    "display(df_all_chronic2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, len(df_all_chronic2) * 0.35))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "table = ax.table(cellText=df_all_chronic2.values,\n",
    "                 colLabels=df_all_chronic2.columns,\n",
    "                 cellLoc='center',\n",
    "                 loc='center')\n",
    "ax.set_title(\"ALL_CHRONIC2: Single-Feature Logistic Regression Results (%)\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/all_chronic2_results.jpg\", dpi=300)\n",
    "plt.show()"
   ],
   "id": "a9629a3f8f9674a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f26dbc8-2a5f-492b-9f10-c08b464113ac",
   "metadata": {},
   "source": [
    "###RANDOM FOREST BASELINE\n",
    "\n",
    "# Run Random Forest on all features at once\n",
    "rf_all_chronic_scores = j_process.run_rf_model(df_rawtrain, df_rawval, feature_list, \"ALL_CHRONIC\")\n",
    "rf_all_cardiac_scores = j_process.run_rf_model(df_rawtrain, df_rawval, feature_list, \"ALL_CARDIAC\")\n",
    "rf_all_pul_scores = j_process.run_rf_model(df_rawtrain, df_rawval, feature_list, \"ALL_PUL\")\n",
    "rf_chronic2_scores = j_process.run_rf_model(df_rawtrain,df_rawval,feature_list,\"ALL_CHRONIC2\")\n",
    "\n",
    "rfsummary_df = pd.DataFrame([\n",
    "    summarize_model_results('ALL_CHRONIC', rf_all_chronic_scores),\n",
    "    summarize_model_results('ALL_CARDIAC', rf_all_cardiac_scores),\n",
    "    summarize_model_results('ALL_PUL', rf_all_pul_scores),\n",
    "    summarize_model_results('ALL_CHRONIC2', rf_chronic2_scores)\n",
    "])\n",
    "\n",
    "\n",
    "print(rfsummary_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Scale and round the values\n",
    "rf_table = rfsummary_df.copy()\n",
    "for col in rf_table.columns:\n",
    "    if col != 'Model':\n",
    "        rf_table[col] = (rf_table[col] * 100).round(3)\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(12, 3))  # Adjust width as needed\n",
    "ax.axis('off')\n",
    "\n",
    "# Create table with padding and font size\n",
    "table = ax.table(\n",
    "    cellText=rf_table.values,\n",
    "    colLabels=rf_table.columns,\n",
    "    cellLoc='center',\n",
    "    loc='center',\n",
    "    bbox=[0, 0, 1, 1]\n",
    ")\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "\n",
    "# Set column widths more evenly\n",
    "col_width = 1.0 / (len(rf_table.columns) + 1)\n",
    "for i in range(len(rf_table.columns)):\n",
    "    table.auto_set_column_width(i)\n",
    "\n",
    "# Title\n",
    "ax.set_title(\"Random Forest Validation Metrics (%)\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "\n",
    "# Save\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/rf_validation_results_fixed.jpg\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "465fbeeec5c82c4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f01ebc15-c5f9-475b-8f65-1ec20e3d45ac",
   "metadata": {},
   "source": [
    "#### Skipped this section, this is redundant\n",
    "\n",
    "if redundant == False:\n",
    "    print(\"skipping redundant tests\")\n",
    "else:\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    rf_all_chronic_results_dict = {}\n",
    "    rf_all_cardiac_results_dict = {}\n",
    "    rf_all_pul_results_dict = {}\n",
    "    rf_all_chronic2_results_dict={}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    rf_result_dicts = {\n",
    "        \"ALL_CHRONIC\": rf_all_chronic_results_dict,\n",
    "        \"ALL_CARDIAC\": rf_all_cardiac_results_dict,\n",
    "        \"ALL_PUL\": rf_all_pul_results_dict,\n",
    "        \"ALL_CHRONIC2\": rf_all_chronic2_results_dict\n",
    "    }\n",
    "    \n",
    "    for label in target_labels:\n",
    "        for feature in feature_list:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"\\n---Running RF baseline on feature: {feature} [{label}] ---\")\n",
    "            results = j_process.run_rf_model(df_rawtrain, df_rawval, [feature], label)\n",
    "            rf_result_dicts[label][feature] = results\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e15dae31-a4df-4a6f-a297-65ef32541a6f",
   "metadata": {},
   "source": [
    "#####TENSOR FLOW BASELINE\n",
    "\n",
    "tf_all_chronic_scores = j_process.run_tf_model(df_rawtrain, df_rawval, feature_list, \"ALL_CHRONIC\",verbose=0)\n",
    "tf_all_cardiac_scores = j_process.run_tf_model(df_rawtrain, df_rawval, feature_list, \"ALL_CARDIAC\")\n",
    "tf_all_pul_scores = j_process.run_tf_model(df_rawtrain, df_rawval, feature_list, \"ALL_PUL\")\n",
    "tf_chronic2_scores = j_process.run_tf_model(df_rawtrain,df_rawval,feature_list,\"ALL_CHRONIC2\")\n",
    "tfsummary_df = pd.DataFrame([\n",
    "    summarize_model_results('ALL_CHRONIC', tf_all_chronic_scores),\n",
    "    summarize_model_results('ALL_CARDIAC', tf_all_cardiac_scores),\n",
    "    summarize_model_results('ALL_PUL', tf_all_pul_scores),\n",
    "    summarize_model_results('ALL_CHRONIC2', tf_chronic2_scores)\n",
    "])\n",
    "\n",
    "\n",
    "print(tfsummary_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare table\n",
    "tf_table = tfsummary_df.copy()\n",
    "for col in tf_table.columns:\n",
    "    if col != 'Model':\n",
    "        tf_table[col] = (tf_table[col] * 100).round(3)\n",
    "\n",
    "# Plot table as image\n",
    "fig, ax = plt.subplots(figsize=(12, 3))  # Widen as needed\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(\n",
    "    cellText=tf_table.values,\n",
    "    colLabels=tf_table.columns,\n",
    "    cellLoc='center',\n",
    "    loc='center',\n",
    "    bbox=[0, 0, 1, 1]\n",
    ")\n",
    "\n",
    "# Font and layout fixes\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "for i in range(len(tf_table.columns)):\n",
    "    table.auto_set_column_width(i)\n",
    "\n",
    "ax.set_title(\"TensorFlow Validation Metrics (%)\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/tf_validation_results.jpg\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "30f6e3540374abbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "449b4402-1ef1-4987-9b5c-b00aa051c421",
   "metadata": {},
   "source": [
    "######Redundant section, can be skipped. Will run if 'skip' is set to False at the import section\n",
    "\n",
    "\n",
    "if redundant == False:\n",
    "    print(\"skipping redundant tests\")\n",
    "else:\n",
    "\n",
    "    ####Tensor flow output\n",
    "    # Prepare per-feature result dicts\n",
    "    tf_all_chronic_results_dict = {}\n",
    "    tf_all_cardiac_results_dict = {}\n",
    "    tf_all_pul_results_dict = {}\n",
    "    tf_all_chronic2_results_dict={}\n",
    "    # Individual feature runs for ALL_CHRONIC\n",
    "    for feature in feature_list:\n",
    "        print(f\"\\n---Running baseline on feature: {feature} [ALL_CHRONIC] ---\")\n",
    "        results = j_process.run_tf_model(df_rawtrain, df_rawval, [feature], \"ALL_CHRONIC\")\n",
    "        tf_all_chronic_results_dict[feature] = results\n",
    "    \n",
    "    # Individual feature runs for ALL_CARDIAC\n",
    "    for feature in feature_list:\n",
    "        print(f\"\\n---Running baseline on feature: {feature} [ALL_CARDIAC] ---\")\n",
    "        results = j_process.run_tf_model(df_rawtrain, df_rawval, [feature], \"ALL_CARDIAC\")\n",
    "        tf_all_cardiac_results_dict[feature] = results\n",
    "    \n",
    "    # Individual feature runs for ALL_PUL\n",
    "    for feature in feature_list:\n",
    "        print(f\"\\n---Running baseline on feature: {feature} [ALL_PUL] ---\")\n",
    "        results = j_process.run_tf_model(df_rawtrain, df_rawval, [feature], \"ALL_PUL\")\n",
    "        tf_all_pul_results_dict[feature] = results\n",
    "    for feature in feature_list:\n",
    "        print(f\"\\n---Running baseline on feature: {feature} [ALL_CHRONIC2] ---\")\n",
    "        results = j_process.run_tf_model(df_rawtrain, df_rawval, [feature], \"ALL_CHRONIC2\")\n",
    "        tf_all_chronic2_results_dict[feature] = results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3407156e-9fe0-4508-a3fa-84711c560403",
   "metadata": {},
   "source": [
    "## Cluster with selected K's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d1b01a-87f6-4740-b7dc-60178847a182",
   "metadata": {},
   "source": [
    "### Kmodes"
   ]
  },
  {
   "cell_type": "code",
   "id": "fabee702-4298-4d96-9bb2-7a71e5e863d5",
   "metadata": {},
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "k_trials = [2,3,4,5,6,7,8,9,10,15,20,25,35,40,50,100]\n",
    "\n",
    "cluster_df_train = df_train.copy()\n",
    "cluster_df_val = df_val.copy()\n",
    "cluster_columns = []\n",
    "\n",
    "if skip == True:\n",
    "    cluster_df_train = pd.read_parquet(\"data/cluster_df_train.parquet\")\n",
    "    cluster_df_val = pd.read_parquet(\"data/cluster_df_val.parquet\")\n",
    "    print(\"Data loaded...\")\n",
    "    print(cluster_df_train.head())\n",
    "else:\n",
    "    def run_kmodes_parallel(trial, df, feature_list):\n",
    "        print(f\"[K-Modes] {trial} clusters\")\n",
    "        updated_df, col_name, _ = j_process.run_kmodes_cluster(\n",
    "            df.copy(), feature_cols=feature_list, n_clusters=trial\n",
    "        )\n",
    "        return updated_df[col_name], col_name\n",
    "\n",
    "    # Train set in parallel\n",
    "    results_train = Parallel(n_jobs=-1)(\n",
    "        delayed(run_kmodes_parallel)(trial, cluster_df_train, feature_list)\n",
    "        for trial in k_trials\n",
    "    )\n",
    "\n",
    "    for col_series, col_name in results_train:\n",
    "        cluster_df_train[col_name] = col_series\n",
    "        cluster_columns.append(col_name)\n",
    "\n",
    "    # Val set in parallel\n",
    "    results_val = Parallel(n_jobs=-1)(\n",
    "        delayed(run_kmodes_parallel)(trial, cluster_df_val, feature_list)\n",
    "        for trial in k_trials\n",
    "    )\n",
    "\n",
    "    for col_series, col_name in results_val:\n",
    "        cluster_df_val[col_name] = col_series\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4c456741-4606-4f1f-a9fd-9d1b08071130",
   "metadata": {},
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "id": "934c7b78-abf9-4460-9e59-2f4cc022ef5d",
   "metadata": {},
   "source": [
    "if skip == True:\n",
    "    print(\"skipping...\")\n",
    "    \n",
    "else:\n",
    "    for trial in k_trials:\n",
    "        print(f\"[TF Clustering] {trial} clusters\")\n",
    "        print(\"Train Set\")\n",
    "        cluster_df_train, col_train = j_process.run_tf_clustering(\n",
    "            cluster_df_train, feature_cols=feature_list, n_clusters=trial\n",
    "        )\n",
    "        cluster_columns.append(col_train)\n",
    "        print(\"Val Set\")\n",
    "        cluster_df_val, _ = j_process.run_tf_clustering(\n",
    "            cluster_df_val, feature_cols=feature_list, n_clusters=trial\n",
    "        )\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1983112a-5ff0-424d-9b61-18529914b84e",
   "metadata": {},
   "source": [
    "if skip==True:\n",
    "    print(\"No need to save....\")\n",
    "else:\n",
    "    j_process.p_save(cluster_df_val,\"data/cluster_df_val.parquet\")\n",
    "    j_process.p_save(cluster_df_train,\"data/cluster_df_train.parquet\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "482d02e0-57b0-4744-b499-57b0dc3dd126",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "\n",
    "\n",
    "for km in cluster_columns:\n",
    "    print(km)\n",
    "clustering_only=[]\n",
    "\n",
    "#print(cluster_df_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a78ee5b9-ed16-4370-a14d-762e903c3ddc",
   "metadata": {},
   "source": [
    "\n",
    "for km in cluster_columns:\n",
    "    for target in target_labels:\n",
    "        print(km)\n",
    "        results = j_process.run_logistic_model(cluster_df_train,cluster_df_val,feature_list+[km],target)\n",
    "        print(km)\n",
    "        clustering_only.append(results)\n",
    "        results = j_process.run_tf_model(cluster_df_train,cluster_df_val,feature_list+[km],target,verbose=1)\n",
    "        clustering_only.append(results)\n",
    "        results = j_process.run_rf_model(cluster_df_train,cluster_df_val,feature_list+[km],target)\n",
    "        clustering_only.append(results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "960eeab0-2f76-4308-9402-dfeb35a007f9",
   "metadata": {},
   "source": [
    "print(cluster_df_train.head())\n",
    "print(feature_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7defb514-09a5-42d5-b5b7-7444f815cafd",
   "metadata": {},
   "source": [
    "\n",
    "cluster_col = 'tf_n4_d8_e50'\n",
    "cluster_val = 3\n",
    "\n",
    "\n",
    "target_cols = ['ALL_CHRONIC', 'ALL_CARDIAC', 'ALL_PUL', 'ALL_CANCER','ALL_CHRONIC2']\n",
    "subset = cluster_df_train[cluster_df_train[cluster_col] == cluster_val]\n",
    "\n",
    "\n",
    "yes_counts = []\n",
    "no_counts = []\n",
    "\n",
    "for col in target_cols:\n",
    "    vc = subset[col].value_counts()\n",
    "    yes_counts.append(vc.get('Yes', 0))\n",
    "    no_counts.append(vc.get('No', 0))\n",
    "\n",
    "# Step 4: Plot stacked bar\n",
    "x = target_cols\n",
    "x_pos = range(len(x))\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.bar(x_pos, yes_counts, label='Yes', color='steelblue')\n",
    "plt.bar(x_pos, no_counts, bottom=yes_counts, label='No', color='lightgray')\n",
    "\n",
    "plt.xticks(x_pos, x, rotation=45)\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'\"Yes\" and \"No\" Counts for {cluster_col} = {cluster_val}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "75d3089e-9bf1-4222-b5ee-cac7090d361d",
   "metadata": {},
   "source": [
    "plot_cols = [col for col in cluster_df_train.columns if col.startswith('kmode') or col.startswith('tf')]\n",
    "\n",
    "for col in plot_cols:\n",
    "    counts = cluster_df_train[col].value_counts().sort_values(ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    counts.plot(kind='bar')\n",
    "    plt.title(f'Value Counts for {col}')\n",
    "    plt.xlabel('Cluster Label')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8c8a803b-1f79-4e21-9567-b4db974d3616",
   "metadata": {},
   "source": [
    "## MCA Dimensonality reduction"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb707981-de26-4f61-ba70-c472e1d2f62b",
   "metadata": {},
   "source": [
    "mca_df_train = df_train.copy()\n",
    "mca_df_val = df_val.copy()\n",
    "print(feature_list)\n",
    "mca_df_train=mca_df_train[feature_list]\n",
    "mca_df_val=mca_df_val[feature_list]\n",
    "print(mca_df_train.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "47d1f759-6f7d-4ad5-86b8-a4dcaff0bfe4",
   "metadata": {},
   "source": [
    "### Mca analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "2f57be98-a936-4bdf-87cc-b2d26663ab8d",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "mca_results = []\n",
    "\n",
    "for n_components in sorted(mca_set.keys()):\n",
    "    # Step 1: Run MCA on dropped-column (feature-only) data\n",
    "    train_mca = j_process.run_mca(mca_set[n_components], n_components=n_components)\n",
    "    val_mca = j_process.run_mca(mca_val[n_components], n_components=n_components)\n",
    "\n",
    "    # Rename MCA columns to ensure uniqueness\n",
    "    train_mca.columns = [f\"mca_{n_components}_{i}\" for i in range(n_components)]\n",
    "    val_mca.columns = [f\"mca_{n_components}_{i}\" for i in range(n_components)]\n",
    "\n",
    "    # Step 2: Reattach targets\n",
    "    train_combined = pd.concat([train_mca, df_train[target_labels].reset_index(drop=True)], axis=1)\n",
    "    val_combined = pd.concat([val_mca, df_val[target_labels].reset_index(drop=True)], axis=1)\n",
    "\n",
    "    mca_feat_cols = train_mca.columns.tolist()\n",
    "\n",
    "    # Step 3: Run models\n",
    "    for target in target_labels:\n",
    "        print(f\"Running MCA={n_components}, Target={target}...\")\n",
    "\n",
    "        log_results = j_process.run_logistic_model(train_combined, val_combined, mca_feat_cols, target)\n",
    "        log_results.update({\n",
    "            \"Model\": \"Logistic\",\n",
    "            \"Target\": target,\n",
    "            \"MCA Components\": n_components\n",
    "        })\n",
    "        mca_results.append(log_results)\n",
    "\n",
    "        tf_results = j_process.run_tf_model(train_combined, val_combined, mca_feat_cols, target, verbose=0)\n",
    "        tf_results.update({\n",
    "            \"Model\": \"TensorFlow\",\n",
    "            \"Target\": target,\n",
    "            \"MCA Components\": n_components\n",
    "        })\n",
    "        mca_results.append(tf_results)\n",
    "\n",
    "# Step 4: Create summary table\n",
    "df_mca_all = pd.DataFrame(mca_results)\n",
    "df_mca_all = df_mca_all[[\"MCA Components\", \"Target\", \"Model\", \"accuracy\", \"precision\", \"recall\", \"f1_score\"]]\n",
    "\n",
    "for col in [\"accuracy\", \"precision\", \"recall\", \"f1_score\"]:\n",
    "    df_mca_all[col] = (df_mca_all[col] * 100).round(3)\n",
    "\n",
    "display(df_mca_all)\n",
    "\n",
    "# Step 5: Save one image per MCA component count\n",
    "for comp in sorted(df_mca_all[\"MCA Components\"].unique()):\n",
    "    subset = df_mca_all[df_mca_all[\"MCA Components\"] == comp]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 0.5 + len(subset) * 0.5))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "\n",
    "    table = ax.table(\n",
    "        cellText=subset.values,\n",
    "        colLabels=subset.columns,\n",
    "        cellLoc='center',\n",
    "        loc='center',\n",
    "        bbox=[0, 0, 1, 1]\n",
    "    )\n",
    "\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "\n",
    "    ax.set_title(f\"MCA-{comp} Model Results (%)\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"images/mca_{comp}_results.jpg\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a65d6590-2157-495f-aaa4-90e266655bee",
   "metadata": {},
   "source": [
    "print(feature_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e14c03b-ea4f-4659-93b6-de5098928e24",
   "metadata": {},
   "source": [
    "# Keep only columns starting with 'mca_' or 'ALL_'\n",
    "#mca2_df_train = mca2_df_train[[col for col in mca2_df_train.columns if col.startswith(\"mca_\") or col.startswith(\"ALL_\")]]\n",
    "#mca2_df_val = mca2_df_val[[col for col in mca2_dgf_val.columns if col.startswith(\"mca_\") or col.startswith(\"ALL_\")]]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd931911-04d3-4fdf-ad95-6234f9ba4499",
   "metadata": {},
   "source": [
    "for comp in df_mca_all[\"MCA Components\"].unique():\n",
    "    subset = df_mca_all[df_mca_all[\"MCA Components\"] == comp]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, len(subset) * 0.5))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    table = ax.table(\n",
    "        cellText=subset.values,\n",
    "        colLabels=subset.columns,\n",
    "        cellLoc='center',\n",
    "        loc='center',\n",
    "        bbox=[0, 0, 1, 1]\n",
    "    )\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    ax.set_title(f\"MCA-{comp} Model Results (%)\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"images/mca_{comp}_results.jpg\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f3bae2a-a507-4631-8901-dd8e1f98429f",
   "metadata": {},
   "source": [
    "print(mca_only)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "350e96a5-6502-4945-8b2a-2c74018e12f0",
   "metadata": {},
   "source": [
    "print(mca_only)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "367e1d97-0fd2-434b-b704-6211cee095a0",
   "metadata": {},
   "source": [
    "print(mca_set.head())\n",
    "print(combined_feat)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import ipywidgets as widgets\n",
    "df = cluster_df_train.copy()\n",
    "\n",
    "# Split column names into kmode and tf lists\n",
    "kmode_cols = [col for col in df.columns if col.startswith('kmode')]\n",
    "tf_cols = [col for col in df.columns if col.startswith('tf')]\n",
    "\n",
    "# Dropdown widget\n",
    "col_type = widgets.Dropdown(\n",
    "    options=['kmode', 'tf'],\n",
    "    description='Type:'\n",
    ")\n",
    "\n",
    "# Dropdown widget for specific column (updated dynamically)\n",
    "col_dropdown = widgets.Dropdown(description='Column:')\n",
    "\n",
    "# Output area for the plot\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to update column dropdown based on type\n",
    "def update_col_dropdown(*args):\n",
    "    if col_type.value == 'kmode':\n",
    "        col_dropdown.options = kmode_cols\n",
    "    else:\n",
    "        col_dropdown.options = tf_cols\n",
    "\n",
    "# Plotting function\n",
    "def plot_column_counts(change):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        col = col_dropdown.value\n",
    "        if col:\n",
    "            counts = df[col].value_counts().sort_index()\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            counts.plot(kind='bar')\n",
    "            plt.title(f'Value Counts for {col}')\n",
    "            plt.xlabel('Value')\n",
    "            plt.ylabel('Count')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "col_type.observe(update_col_dropdown, names='value')\n",
    "col_dropdown.observe(plot_column_counts, names='value')\n",
    "\n",
    "# Initialize dropdown\n",
    "update_col_dropdown()\n",
    "\n",
    "# Display widgets\n",
    "display(widgets.VBox([col_type, col_dropdown, output]))"
   ],
   "id": "e99a119479fb6bb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "feature_list_1 = feature_list\n",
    "feature_list_2 = target_cols\n",
    "\n",
    "\n",
    "cluster_cols = [col for col in df.columns if col.startswith(\"kmode\") or col.startswith(\"tf\")]\n",
    "\n",
    "cluster_col_dropdown = widgets.Dropdown(options=cluster_cols, description='Cluster Column:')\n",
    "cluster_val_dropdown = widgets.Dropdown(description='Cluster Value:')\n",
    "feature_set_dropdown = widgets.Dropdown(options=['Feature Set 1', 'Feature Set 2'], description='Feature Set:')\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def update_cluster_vals(*args):\n",
    "    selected_col = cluster_col_dropdown.value\n",
    "    if selected_col:\n",
    "        cluster_val_dropdown.options = sorted(df[selected_col].dropna().unique())\n",
    "\n",
    "\n",
    "def plot_stacked_bar(*args):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        cluster_col = cluster_col_dropdown.value\n",
    "        cluster_val = cluster_val_dropdown.value\n",
    "\n",
    "        if feature_set_dropdown.value == 'Feature Set 1':\n",
    "            features = feature_list_1\n",
    "        else:\n",
    "            features = feature_list_2\n",
    "\n",
    "\n",
    "        filtered = df[df[cluster_col] == cluster_val]\n",
    "\n",
    "\n",
    "        records = []\n",
    "        for col in features:\n",
    "            total = filtered[col].notna().sum()\n",
    "            counts = filtered[col].value_counts(dropna=False)\n",
    "            for val, count in counts.items():\n",
    "                pct = 100 * count / total if total else 0\n",
    "                records.append({\n",
    "                    'Feature': col,\n",
    "                    'Response': str(val),\n",
    "                    'Count': count,\n",
    "                    'Percentage': f\"{pct:.1f}%\"\n",
    "                })\n",
    "\n",
    "        plot_df = pd.DataFrame(records)\n",
    "\n",
    "\n",
    "        response_order = [\"No\", \"Yes\", \"Refused\", \"Don't know\", \"Missing\"]\n",
    "        color_map = {\n",
    "            \"No\": \"#636EFA\",\n",
    "            \"Yes\": \"#00CC96\",\n",
    "            \"Refused\": \"#FFA15A\",\n",
    "            \"Don't know\": \"#AB63FA\",\n",
    "            \"Missing\": \"#B6E880\"\n",
    "        }\n",
    "\n",
    "        plot_df[\"Response\"] = pd.Categorical(plot_df[\"Response\"], categories=response_order, ordered=True)\n",
    "        plot_df = plot_df.sort_values(\"Response\")  # Enforce consistent stacking\n",
    "\n",
    "        fig = px.bar(\n",
    "            plot_df,\n",
    "            x='Feature',\n",
    "            y='Count',\n",
    "            color='Response',\n",
    "            text='Percentage',\n",
    "            hover_data={'Count': True, 'Percentage': True, 'Response': True},\n",
    "            color_discrete_map=color_map\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            barmode='stack',\n",
    "            title=f'Stacked Bar: Cluster {cluster_val} in {cluster_col}',\n",
    "            xaxis_title='Feature',\n",
    "            yaxis_title='Count',\n",
    "            showlegend=False\n",
    "        )\n",
    "\n",
    "        fig.update_traces(textposition='inside')\n",
    "        fig.show()\n",
    "cluster_col_dropdown.observe(update_cluster_vals, names='value')\n",
    "cluster_val_dropdown.observe(plot_stacked_bar, names='value')\n",
    "feature_set_dropdown.observe(plot_stacked_bar, names='value')\n",
    "update_cluster_vals()\n",
    "display(widgets.VBox([\n",
    "    cluster_col_dropdown,\n",
    "    cluster_val_dropdown,\n",
    "    feature_set_dropdown,\n",
    "    output\n",
    "]))\n"
   ],
   "id": "c7b7e14d63ef911a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from PIL import Image\n",
    "from fpdf import FPDF\n",
    "from datetime import datetime\n",
    "\n",
    "# PDF setup\n",
    "pdf = FPDF()\n",
    "pdf.set_auto_page_break(auto=True, margin=15)\n",
    "\n",
    "# Folder with images\n",
    "image_dir = 'images/'\n",
    "\n",
    "# Get all image files with their creation time\n",
    "image_files = [\n",
    "    (f, os.path.getctime(os.path.join(image_dir, f)))\n",
    "    for f in os.listdir(image_dir)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "]\n",
    "\n",
    "# Sort by creation time\n",
    "image_files.sort(key=lambda x: x[1])\n",
    "\n",
    "# Add each image to the PDF\n",
    "for i, (filename, ctime) in enumerate(image_files, start=1):\n",
    "    filepath = os.path.join(image_dir, filename)\n",
    "\n",
    "    pdf.add_page()\n",
    "\n",
    "    title = os.path.splitext(filename)[0]\n",
    "    date_str = datetime.fromtimestamp(ctime).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    pdf.set_font(\"Arial\", size=14)\n",
    "    pdf.cell(0, 10, f\"Fig {i}: {title}\", ln=True)\n",
    "    pdf.set_font(\"Arial\", size=10)\n",
    "    pdf.cell(0, 10, f\"Created: {date_str}\", ln=True)\n",
    "\n",
    "    # Resize image to fit page\n",
    "    im = Image.open(filepath)\n",
    "    width, height = im.size\n",
    "    aspect = width / height\n",
    "    max_width, max_height = 180, 180 / aspect\n",
    "    pdf.image(filepath, x=15, y=40, w=max_width)\n",
    "\n",
    "# Save PDF\n",
    "pdf.output(\"output.pdf\")\n"
   ],
   "id": "48dd43642d5eae4f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
